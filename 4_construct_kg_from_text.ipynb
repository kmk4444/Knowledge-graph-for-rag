{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/kmk4444/Knowledge-graph-for-rag/blob/main/4_construct_kg_from_text.ipynb",
      "authorship_tag": "ABX9TyP1hrGND6uuIsPr1n9v5esi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmk4444/Knowledge-graph-for-rag/blob/main/4_construct_kg_from_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson 4: Constructing a Knowledge Graph from Text Documents"
      ],
      "metadata": {
        "id": "zK6qbuUwChuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import packages and set up Neo4j"
      ],
      "metadata": {
        "id": "n-qx8YQMCjNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community neo4j python-dotenv langchain-openai"
      ],
      "metadata": {
        "id": "GB9bHeIFCp3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ul4TAoW6CAAx"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Common data processing\n",
        "import json\n",
        "import textwrap\n",
        "\n",
        "# Langchain\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kJyjquP8ptNx"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Take a look at a Form 10-K json file\n",
        "\n"
      ],
      "metadata": {
        "id": "qeQwiFYfqAdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_file_name = \"/content/drive/MyDrive/0000950170-23-027948.json\""
      ],
      "metadata": {
        "id": "3BHvabFNp3IH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_file_as_object = json.load(open(first_file_name))"
      ],
      "metadata": {
        "id": "Iznj8CpitRsl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(first_file_as_object)"
      ],
      "metadata": {
        "id": "cwkNGwnTuKTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k,v in first_file_as_object.items():\n",
        "    print(k, type(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odSNGp47uMWT",
        "outputId": "b3e2c625-67a7-4c58-9fd7-0fce792851c0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "item1 <class 'str'>\n",
            "item1a <class 'str'>\n",
            "item7 <class 'str'>\n",
            "item7a <class 'str'>\n",
            "cik <class 'str'>\n",
            "cusip6 <class 'str'>\n",
            "cusip <class 'list'>\n",
            "names <class 'list'>\n",
            "source <class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "item1_text = first_file_as_object['item1']"
      ],
      "metadata": {
        "id": "Ref4Hjc-vOrj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item1_text[0:]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ipLzpPvhvQga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Form 10-K sections into chunks\n",
        "- Set up text splitter using LangChain\n",
        "- For now, split only the text from the \"item 1\" section"
      ],
      "metadata": {
        "id": "zlSfaRfSv0_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 2000,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        "    is_separator_regex = False,\n",
        ")"
      ],
      "metadata": {
        "id": "GYuwr-jsv1qA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item1_text_chunks = text_splitter.split_text(item1_text)"
      ],
      "metadata": {
        "id": "Wr4mydhkwzNd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(item1_text_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LYFgHBWxH_o",
        "outputId": "49303b59-f1e8-4513-dcfa-36db43a962bf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(item1_text_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fVzow6sxPBU",
        "outputId": "6e5c1a60-0385-4a60-a6a3-d64fcef6cfcd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "254"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "item1_text_chunks[0]"
      ],
      "metadata": {
        "id": "s4il3I8BxZIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Set up helper function to chunk all sections of the Form 10-K\n",
        "- You'll limit the number of chunks in each section to 20 to speed things up"
      ],
      "metadata": {
        "id": "wPfHVtAzxksu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_form10k_data_from_file(file):\n",
        "    chunks_with_metadata = [] # use this to accumlate chunk records\n",
        "    file_as_object = json.load(open(file)) # open the json file\n",
        "    for item in ['item1','item1a','item7','item7a']: # pull these keys from the json\n",
        "        print(f'Processing {item} from {file}')\n",
        "        item_text = file_as_object[item] # grab the text of the item\n",
        "        item_text_chunks = text_splitter.split_text(item_text) # split the text into chunks\n",
        "        chunk_seq_id = 0\n",
        "        for chunk in item_text_chunks[:20]: # only take the first 20 chunks\n",
        "            form_id = file[file.rindex('/') + 1:file.rindex('.')] # extract form id from file name\n",
        "            # finally, construct a record with metadata and the chunk text\n",
        "            chunks_with_metadata.append({\n",
        "                'text': chunk,\n",
        "                # metadata from looping...\n",
        "                'f10kItem': item,\n",
        "                'chunkSeqId': chunk_seq_id,\n",
        "                # constructed metadata...\n",
        "                'formId': f'{form_id}', # pulled from the filename\n",
        "                'chunkId': f'{form_id}-{item}-chunk{chunk_seq_id:04d}',\n",
        "                # metadata from file...\n",
        "                'names': file_as_object['names'],\n",
        "                'cik': file_as_object['cik'],\n",
        "                'cusip6': file_as_object['cusip6'],\n",
        "                'source': file_as_object['source'],\n",
        "            })\n",
        "            chunk_seq_id += 1\n",
        "        print(f'\\tSplit into {chunk_seq_id} chunks')\n",
        "    return chunks_with_metadata"
      ],
      "metadata": {
        "id": "pvUaUYsFxjco"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_file_chunks = split_form10k_data_from_file(first_file_name)"
      ],
      "metadata": {
        "id": "gV6BQw2f3IcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_file_chunks[0]"
      ],
      "metadata": {
        "id": "UgoxCM_83S8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create graph nodes using text chunks"
      ],
      "metadata": {
        "id": "aUsToj7T3_N_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merge_chunk_node_query = \"\"\"\n",
        "MERGE(mergedChunk:Chunk {chunkId: $chunkParam.chunkId})\n",
        "    ON CREATE SET\n",
        "        mergedChunk.names = $chunkParam.names,\n",
        "        mergedChunk.formId = $chunkParam.formId,\n",
        "        mergedChunk.cik = $chunkParam.cik,\n",
        "        mergedChunk.cusip6 = $chunkParam.cusip6,\n",
        "        mergedChunk.source = $chunkParam.source,\n",
        "        mergedChunk.f10kItem = $chunkParam.f10kItem,\n",
        "        mergedChunk.chunkSeqId = $chunkParam.chunkSeqId,\n",
        "        mergedChunk.text = $chunkParam.text\n",
        "RETURN mergedChunk\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-rQNjQGC39y5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Set up connection to graph instance using LangChain"
      ],
      "metadata": {
        "id": "gJSNowbf4BoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kg = Neo4jGraph(\n",
        "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
        ")"
      ],
      "metadata": {
        "id": "qklfKq1q4CNv"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create a single chunk node for now"
      ],
      "metadata": {
        "id": "W0TBpSva6ILB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(merge_chunk_node_query,\n",
        "         params={'chunkParam':first_file_chunks[0]})"
      ],
      "metadata": {
        "id": "494ot5no6JWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create a uniqueness constraint to avoid duplicate chunks"
      ],
      "metadata": {
        "id": "F0ykXKXn6OIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"\"\"\n",
        "CREATE CONSTRAINT unique_chunk IF NOT EXISTS\n",
        "    FOR (c:Chunk) REQUIRE c.chunkId IS UNIQUE\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfkKFsls6O8b",
        "outputId": "57ffd32e-2b52-47fd-c6b2-2e3770f06fc5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"SHOW INDEXES\")"
      ],
      "metadata": {
        "id": "R583iGrY6SMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Loop through and create nodes for all chunks\n",
        "- Should create 23 nodes because you set a limit of 20 chunks in the text splitting function above"
      ],
      "metadata": {
        "id": "ADmRbAvo6ldL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_count = 0\n",
        "for chunk in first_file_chunks:\n",
        "    print(f\"Creating `:Chunk` node for chunk ID {chunk['chunkId']}\")\n",
        "    kg.query(merge_chunk_node_query,\n",
        "            params={\n",
        "                'chunkParam': chunk\n",
        "            })\n",
        "    node_count += 1\n",
        "print(f\"Created {node_count} nodes\")"
      ],
      "metadata": {
        "id": "1ludiiND6mPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"\"\"\n",
        "         MATCH (n)\n",
        "         RETURN count(n) as nodeCount\n",
        "         \"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2Uz2QKr6qS3",
        "outputId": "b7defb43-7dde-45ce-c6bb-5781cced4056"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'nodeCount': 129}]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a vector index"
      ],
      "metadata": {
        "id": "aXOa5LMd6sKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"\"\"\n",
        "         CREATE VECTOR INDEX `form_10k_chunks` IF NOT EXISTS\n",
        "          FOR (c:Chunk) ON (c.textEmbedding)\n",
        "          OPTIONS { indexConfig: {\n",
        "            `vector.dimensions`: 1536,\n",
        "            `vector.similarity_function`: 'cosine'\n",
        "         }}\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJwF7ozu6sv6",
        "outputId": "be5a8bc4-bfb9-478b-98ac-911f5f9e5150"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"SHOW INDEXES\")"
      ],
      "metadata": {
        "id": "xXToNHLe6usD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate embedding vectors for chunks and populate index\n",
        "- This query calculates the embedding vector and stores it as a property called `textEmbedding` on each `Chunk` node."
      ],
      "metadata": {
        "id": "qTyIvUuR6yq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"\"\"\n",
        "    MATCH (chunk:Chunk) WHERE chunk.textEmbedding IS NULL\n",
        "    WITH chunk, genai.vector.encode(\n",
        "      chunk.text,\n",
        "      \"OpenAI\",\n",
        "      {\n",
        "        token: $openAiApiKey\n",
        "      }) AS vector\n",
        "    CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding\", vector)\n",
        "    \"\"\",\n",
        "    params={\"openAiApiKey\":OPENAI_API_KEY} )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKGYgqMB69O1",
        "outputId": "54d3bd49-bc15-44f2-9270-0662f8992809"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg.refresh_schema()\n",
        "print(kg.schema)"
      ],
      "metadata": {
        "id": "NiyCYWyQ7HGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use similarity search to find relevant chunks"
      ],
      "metadata": {
        "id": "Y_IN0VMI7Mar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Setup a help function to perform similarity search using the vector index"
      ],
      "metadata": {
        "id": "M8iM5HwX7Nob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def neo4j_vector_search(question):\n",
        "  \"\"\"Search for similar nodes using the Neo4j vector index\"\"\"\n",
        "  vector_search_query = \"\"\"\n",
        "    WITH genai.vector.encode(\n",
        "      $question,\n",
        "      \"OpenAI\",\n",
        "      {\n",
        "        token: $openAiApiKey\n",
        "      }) AS question_embedding\n",
        "    CALL db.index.vector.queryNodes($index_name, $top_k, question_embedding) yield node, score\n",
        "    RETURN score, node.text AS text\n",
        "  \"\"\"\n",
        "  similar = kg.query(vector_search_query,\n",
        "                     params={\n",
        "                      'question': question,\n",
        "                      'openAiApiKey':OPENAI_API_KEY,\n",
        "                      'index_name':VECTOR_INDEX_NAME,\n",
        "                      'top_k': 10})\n",
        "  return similar"
      ],
      "metadata": {
        "id": "cJehMsHA7NNH"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Ask a question!"
      ],
      "metadata": {
        "id": "IXYpJ-n67Tdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_results = neo4j_vector_search(\n",
        "    'In a single sentence, tell me about Netapp.'\n",
        ")"
      ],
      "metadata": {
        "id": "JvsCjTx37UI_"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_results[0]"
      ],
      "metadata": {
        "id": "wv2vg1nE7Vsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up a LangChain RAG workflow to chat with the form"
      ],
      "metadata": {
        "id": "snP9QAXI7ZD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neo4j_vector_store = Neo4jVector.from_existing_graph(\n",
        "    embedding=OpenAIEmbeddings(),\n",
        "    url=NEO4J_URI,\n",
        "    username=NEO4J_USERNAME,\n",
        "    password=NEO4J_PASSWORD,\n",
        "    index_name=VECTOR_INDEX_NAME,\n",
        "    node_label=VECTOR_NODE_LABEL,\n",
        "    text_node_properties=[VECTOR_SOURCE_PROPERTY],\n",
        "    embedding_node_property=VECTOR_EMBEDDING_PROPERTY,\n",
        ")\n"
      ],
      "metadata": {
        "id": "K0M4OlyN7Zmr"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = neo4j_vector_store.as_retriever()"
      ],
      "metadata": {
        "id": "ywmo6ugb8fQ6"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Set up a RetrievalQAWithSourcesChain to carry out question answering\n",
        "- You can check out the LangChain documentation for this chain [here](https://api.python.langchain.com/en/latest/chains/langchain.chains.qa_with_sources.retrieval.RetrievalQAWithSourcesChain.html)"
      ],
      "metadata": {
        "id": "8Qa3r6hb8h-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    ChatOpenAI(temperature=0),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever\n",
        ")"
      ],
      "metadata": {
        "id": "tYqjsLSP8ivh"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prettychain(question: str) -> str:\n",
        "    \"\"\"Pretty print the chain's response to a question\"\"\"\n",
        "    response = chain({\"question\": question},\n",
        "        return_only_outputs=True,)\n",
        "    print(textwrap.fill(response['answer'], 60))"
      ],
      "metadata": {
        "id": "C573m7UE8kCp"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is Netapp's primary business?\""
      ],
      "metadata": {
        "id": "Ve-b-KKb8mK2"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prettychain(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37YI3YBo8nAb",
        "outputId": "99a343ca-9891-4090-879c-c6dae8ef4216"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NetApp's primary business is enterprise storage and data\n",
            "management, cloud storage, and cloud operations.\n"
          ]
        }
      ]
    }
  ]
}